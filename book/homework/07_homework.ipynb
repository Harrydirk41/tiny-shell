{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "hide-input",
          "hide-output"
        ],
        "id": "AVGqAXK9XJ5S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('png')\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\")\n",
        "sns.set_style(\"ticks\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDwFb3QOXJ5U"
      },
      "source": [
        "# Homework 7\n",
        "\n",
        "## References\n",
        "\n",
        "+ Module 5: Inverse problems in deterministic scientifc models\n",
        "    - Purely data-driven learning of dynamical systems\n",
        "\n",
        "+ Module 6: Physics-informed neural networks\n",
        "   - PINNs basics\n",
        "   - PINNs for parametric studies\n",
        "   - PINNs for inverse problems\n",
        "\n",
        "<!-- + Module 7: Inverse problems in stochastic scientific models\n",
        "    - Stochastic differential equations -->\n",
        "\n",
        "## Instructions\n",
        "\n",
        "+ Type your name and email in the \"Student details\" section below.\n",
        "+ Develop the code and generate the figures you need to solve the problems using this notebook.\n",
        "+ For the answers that require a mathematical proof or derivation you should type them using latex. If you have never written latex before and you find it exceedingly difficult, we will likely accept handwritten solutions.\n",
        "+ The total homework points are 100. Please note that the problems are not weighed equally.\n",
        "\n",
        "## Student details\n",
        "\n",
        "+ **First Name:**Yikai\n",
        "+ **Last Name:**Liu\n",
        "+ **Email:**liu3307@purdue.edu\n",
        "+ **Used generative AI to complete this assignment (Yes/No):**No\n",
        "+ **Which generative AI tool did you use (if applicable)?:**No"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7L1pYYPXJ5U"
      },
      "source": [
        "# Problem 1 - Partially Observed Lorenz System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zjfngjv7XJ5V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "sigma = 10.0\n",
        "rho = 28.0\n",
        "beta = 8.0 / 3.0\n",
        "dt = 0.01\n",
        "num_steps = int(20.0 / dt)\n",
        "ts = np.linspace(0, 100, num_steps)\n",
        "x0 = np.array([-8.0, 7.0, 27.0])\n",
        "\n",
        "def vector_field(x, t):\n",
        "    return (\n",
        "        sigma * (x[1] - x[0]),\n",
        "        x[0] * (rho - x[2]) - x[1],\n",
        "        x[0] * x[1] - beta * x[2]\n",
        "    )\n",
        "xs = scipy.integrate.odeint(vector_field, x0, ts)\n",
        "\n",
        "# Find the exact derivatives - no noise\n",
        "from jax import vmap, jit\n",
        "vf = jit(vmap(vector_field, in_axes=(0, 0)))\n",
        "dxs = np.array(vf(xs, ts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeIwPr-HXJ5V"
      },
      "source": [
        "The data you should use are these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xcgJSnfHXJ5V"
      },
      "outputs": [],
      "source": [
        "partial_xs = xs[:, 0]\n",
        "partial_dxs = dxs[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysindy"
      ],
      "metadata": {
        "id": "LG-apGEtY_5y",
        "outputId": "0436bee9-1389-49d1-e419-f9a90713434b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysindy\n",
            "  Downloading pysindy-1.7.5-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.11/dist-packages (from pysindy) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pysindy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pysindy) (1.14.1)\n",
            "Collecting derivative (from pysindy)\n",
            "  Downloading derivative-0.6.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.10.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.31.6)\n",
            "Requirement already satisfied: scs!=2.1.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pysindy) (3.2.7.post2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23->pysindy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23->pysindy) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from derivative->pysindy) (8.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pysindy) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=7.1.0->derivative->pysindy) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pysindy) (1.17.0)\n",
            "Downloading pysindy-1.7.5-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading derivative-0.6.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: derivative, pysindy\n",
            "Successfully installed derivative-0.6.3 pysindy-1.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCznvd3FXJ5V"
      },
      "source": [
        "## Part A - Applying SINDY on a partially observed system\n",
        "\n",
        "Try to apply SINDY on `partial_xs` and `partial_dxs`.\n",
        "Just try to express the right-hand-side of the dynamics using a high order polynomial.\n",
        "Do not use anything fancier as there is no way this can work.\n",
        "Demonstrate using some validation data that this doesn't work.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y85XX20PXJ5V",
        "outputId": "65812ab5-7c75-49c8-ade1-f7a2781a59fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [2000, 3]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e809c22d6db8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Split data into training and validation sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m X_train, X_val, dX_train, dX_val = train_test_split(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpartial_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial_dxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2000, 3]"
          ]
        }
      ],
      "source": [
        "# as many code blocks and markdown blocks as you want\n",
        "import jax.numpy as jnp\n",
        "from jax import random, vmap, jit\n",
        "from jax.experimental.ode import odeint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pysindy as ps\n",
        "\n",
        "# Define Lorenz system parameters and vector field\n",
        "sigma, rho, beta = 10.0, 28.0, 8.0 / 3.0\n",
        "dt = 0.01\n",
        "num_steps = int(20.0 / dt)\n",
        "ts = jnp.linspace(0, 100, num_steps)\n",
        "x0 = jnp.array([-8.0, 7.0, 27.0])\n",
        "\n",
        "@jit\n",
        "def vector_field(x, t):\n",
        "    return jnp.array([\n",
        "        sigma * (x[1] - x[0]),\n",
        "        x[0] * (rho - x[2]) - x[1],\n",
        "        x[0] * x[1] - beta * x[2]\n",
        "    ])\n",
        "\n",
        "# Solve the Lorenz system using odeint\n",
        "xs = odeint(vector_field, x0, ts)\n",
        "\n",
        "# Extract partial data and derivatives\n",
        "partial_xs = xs[:, 0]\n",
        "vf = jit(vmap(vector_field, in_axes=(0, 0)))\n",
        "dxs = jnp.array(vf(xs, ts)).T\n",
        "partial_dxs = dxs[:, 0]\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, dX_train, dX_val = train_test_split(\n",
        "    partial_xs.reshape(-1, 1), partial_dxs.reshape(-1, 1), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define and fit the SINDy model\n",
        "model = ps.SINDy(\n",
        "    feature_library=ps.PolynomialLibrary(degree=5),\n",
        "    optimizer=ps.STLSQ(threshold=0.1),\n",
        ")\n",
        "model.fit(X_train, t=dt, x_dot=dX_train)\n",
        "\n",
        "# Simulate the model on validation data\n",
        "X_val_sim = model.simulate(X_val[0], t=ts[:len(X_val)])\n",
        "\n",
        "# (Optional) Visualize the results using matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(ts[:len(X_val)], X_val, label=\"True\")\n",
        "# plt.plot(ts[:len(X_val)], X_val_sim, label=\"SINDy\")\n",
        "# plt.xlabel(\"Time\")\n",
        "# plt.ylabel(\"x\")\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEF7r_GhXJ5W"
      },
      "source": [
        "## Part B - The Hankel Matrix\n",
        "\n",
        "Part A failed because we tried to fit Markovian dynamics to a partially observed state.\n",
        "There are no Markovian dynamics for partially observed states.\n",
        "Partially observed states exhibit effective dynamics that appear to have memory (and noise).\n",
        "The Hankel matrix is a way to create variables that account for memory.\n",
        "We will try two variations.\n",
        "First, we will just try to learn dynamics directly on the columns of the Hankel matrix.\n",
        "This is not going to work if the memory we need is long.\n",
        "Then, we will use SVD to reduce the dimensionality of the Hankel matrix before attempting to learn the dynamics.\n",
        "\n",
        "Your data are $x(t_1),\\dots,x(t_m)$.\n",
        "The Hankel matrix is:\n",
        "\n",
        "$$\n",
        "\\mathbf{H}_\\ell = \\begin{bmatrix}\n",
        "x(t_1) & x(t_2) & x(t_3) & \\dots x(t_{m-\\ell})\\\\\n",
        "x(t_2) & x(t_3) & x(t_4) & \\dots x(t_{m-\\ell+1})\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\dots \\vdots\\\\\n",
        "x(t_\\ell) & x(t_{\\ell+1}) & x(t_{\\ell+3}) \\dots & x(t_m)\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Write a function that forms the Hankel matrix given the data and $\\ell$.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osN1asKIXJ5W"
      },
      "outputs": [],
      "source": [
        "def make_hankel(xs, ell):\n",
        "    \"\"\"Write a good docstring.\"\"\"\n",
        "    # write your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyTixeHjXJ5W"
      },
      "source": [
        "## Part C - Apply SINDY on the Hankel matrix\n",
        "\n",
        "Form the Hankel matrices for $x(t)$ and $\\dot{x}(t)$ for $\\ell=5$.\n",
        "Try to represent the dynamics with a third degree polynomial.\n",
        "Validate your results.\n",
        "Do not expect this work very well.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gao_2yUTXJ5W"
      },
      "outputs": [],
      "source": [
        "# as many code blocks and markdown blocks as you want"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G1-5bvoXJ5W"
      },
      "source": [
        "## Part D - Do SVD on the Hankel matrix\n",
        "\n",
        "Let's pick a big $\\ell$. Say $\\ell = 100$:\n",
        "+ Form the corresponding Hankel matrix and then do SVD on it.\n",
        "+ Plot the explained variance as a function of the number of singular values.\n",
        "+ How much variance do you explain with three dimensions (this is the intrinsic dimensionality of the dynamical system)?\n",
        "+ Visualize the first three POD modes.\n",
        "+ Project the Hankel matrix columns to three dimensions (POD amplitudes/principal components).\n",
        "+ Plot the time series of each one of the principal components.\n",
        "+ Plot the 3D trajectory of the principal components.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMCPdDS7XJ5W"
      },
      "outputs": [],
      "source": [
        "# as many code blocks and markdown blocks as you want"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIe7SJI9XJ5W"
      },
      "source": [
        "## Part E - Find the time derivatives of the principal components of the Hankel matrix\n",
        "\n",
        "To do SINDY, we need to have time derivatives.\n",
        "So, you have to find the time derivatives of the principal components of the Hankel matrix.\n",
        "You have two options:\n",
        "+ Work out analytically how the observed `partial_dxs` will project on the POD modes, or;\n",
        "+ Use numerical differentiation to find the required time derivatives (Google around for the best Python library for numerical differentiation). In this case, simple finite differences should work.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exyhjkZwXJ5W"
      },
      "outputs": [],
      "source": [
        "# as many code blocks and markdown blocks as you want"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDuaWzIbXJ5W"
      },
      "source": [
        "## Part F - Do SINDY on the principal components of the Hankel matrix\n",
        "\n",
        "You are now ready to do SINDY on the principal components of the Hankel matrix.\n",
        "Use a polynomial of degree 5 as the right-hand-side.\n",
        "Try to validate your results.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7uKC5NeXJ5W"
      },
      "outputs": [],
      "source": [
        "# as many code blocks and markdown blocks as you want"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hakIrVXgXJ5X"
      },
      "source": [
        "# Problem 2 - SINDY with measurement noise and no derivatives\n",
        "\n",
        "Let's get back to the Lorenz system. This time, we are going to assume that we have access to the full state, but we do not have the derivative, and the measurements are corrupted by noise.\n",
        "So, your available data are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K5mwrWvXJ5X"
      },
      "outputs": [],
      "source": [
        "eta = 0.01\n",
        "noisy_x = xs + eta * np.random.normal(0, 1.0, xs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XcP0bh-XJ5X"
      },
      "source": [
        "Review the package [derivative](https://pypi.org/project/derivative/) (which part of the `pysindy` ecosystem) and:\n",
        "- Use a suitable method to estimate the derivative dx/dt from the noisy data `noisy_xs`.\n",
        "- Apply SINDY to the denoised data and the numerical derivatives.\n",
        "- Validate your results.\n",
        "\n",
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGIivAaFXJ5X"
      },
      "source": [
        "# Problem 3 - Physics-informed Neural Networks for Solving a Neo-Hookean Hyperelasticity Problem\n",
        "\n",
        "*The original version of this problem was developed by Atharva Hans as a companion to [this](https://youtu.be/o9JaZGWekWQ).\n",
        "\n",
        "Consider a neo-Hookean square body defined on $(x,y) \\in [0,1]^2$. Let $\\mathbf{u}(x,y) = (u_1, u_2)$ describe the displacement field for this body.\n",
        "This body is subjected to the following displacement boundary conditions:\n",
        "\n",
        "$$\n",
        "u_1(0,y) = 0,\n",
        "$$\n",
        "\n",
        "$$\n",
        "u_2(0,y) = 0,\n",
        "$$\n",
        "\n",
        "$$\n",
        "u_1(1,y) = \\delta,\n",
        "$$\n",
        "\n",
        "$$\n",
        "u_2(1,y) = 0,\n",
        "$$\n",
        "\n",
        "with $\\delta$ referring to the applied displacement along the x-direction.\n",
        "\n",
        "For this hyperelastic material, the stored energy $E_b$ in the body can be expressed in as:\n",
        "\n",
        "$$\n",
        "E_b[\\mathbf{u}(\\cdot)] = \\int_{[0,1]^2}\\left\\{\\frac{1}{2}(\\sum_{i=1}^2\\sum_{j=1}^2{F_{ij}^2} - 2)- \\ln(\\det(\\mathbf{F})) + 50\\ln(\\det(\\mathbf{F}))^2\\right\\} dxdy,\n",
        "$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "\\mathbf{F} = \\mathbf{I} + \\nabla \\mathbf{u},\n",
        "$$\n",
        "\n",
        "where $\\mathbf{I}$ is an identity matrix.\n",
        "\n",
        "The final orientation of this body is described by a displacement field that minimizes the stored energy $E_b$.\n",
        "The idea is to use a neural network to approximate the displacement field and train it by minimizing the stored energy $E_b$.\n",
        "\n",
        "To automatically satisfy the boundary conditions, we will use this approximation:\n",
        "$$\n",
        "u_1(x,y) = \\delta - \\delta(1-x) + x(1-x)N_1(x,y;\\theta),\n",
        "$$\n",
        "and,\n",
        "$$\n",
        "u_2(x,y) = x(1-x)N_2(x,y;\\theta)\n",
        "$$\n",
        "where $N_1(x,y;\\theta)$ and $N_2(x,y;\\theta)$ are neural networks.\n",
        "\n",
        "## Part A\n",
        "\n",
        "Solve the problem above for $\\delta=0.1$ using a physics-informed neural network (PINN).\n",
        "Use separate neural networks for $N_1(x,y;\\theta)$ and $N_2(x,y;\\theta)$.\n",
        "Start with a multi-layer perceptron with 3 hidden layers, each with 128 units, and tanh activations.\n",
        "Add a Fourier feature layer at the beginning of the network.\n",
        "Feel free to change the architecture if you think it is necessary.\n",
        "\n",
        "Use `equinox` for the neural networks and `optax` for the optimization.\n",
        "Use a sampling average of 32 collocation points to compute the integral of the stored energy.\n",
        "Use the Adam optimizer with a learning rate of 0.001 for 1000 iterations to debug.\n",
        "Feel free to play with the learning rate, the number of collocation points, and the number of iterations.\n",
        "\n",
        "Show the evolution of the loss function over the iterations.\n",
        "Plot the final displacement field (plot $u_1(x,y)$ and $u_2(x,y)$ separately)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygQ0j5HKXJ5X"
      },
      "source": [
        "*Put your answer here. Use as many markdown and code blocks as you want.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tLlYQUeXJ5X"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AycJkxBXJ5X"
      },
      "source": [
        "## Part B\n",
        "\n",
        "Solve the problem for $\\delta=0.5$ using the same architecture as above.\n",
        "It will likely fail to train.\n",
        "If yes, then use the solution of $\\delta=0.1$ as the initial guess for $\\delta=0.2$, and then use the solution of $\\delta=0.2$ as the initial guess for $\\delta=0.3$, and so on, until you reach $\\delta=0.5$.\n",
        "This is called transfer learning.\n",
        "\n",
        "At the end, plot the final displacement field for $\\delta=0.5$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpSduN3ZXJ5X"
      },
      "source": [
        "*Put your answer here. Use as many markdown and code blocks as you want.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwNWVWSEXJ5X"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeG9Ivi0XJ5X"
      },
      "source": [
        "## Part C\n",
        "\n",
        "Solve the parametric problem for $\\delta \\in [0,0.5]$. That is, build a neural network that takes $\\delta$ as input and outputs the displacement field. To do this:\n",
        "+ Modify the loss function to:\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = \\int_0^{0.5} \\int_{[0,1]^2} \\left\\{\\frac{1}{2}(\\sum_{i}\\sum_{j}{F_{ij}^2} - 2)- \\ln(\\det(\\mathbf{F})) + 50\\ln(\\det(\\mathbf{F}))^2\\right\\} dxdy d\\delta.\n",
        "$$\n",
        "\n",
        "+ Modify the neural networks to take $\\delta$ as input, say $N_1(x,y;\\delta;\\theta)$ and $N_2(x,y;\\delta;\\theta)$. Your field will be $\\mathbf{u}(x,y;\\delta;\\theta)$.\n",
        "Use the following architecture for the neural networks:\n",
        "\n",
        "$$\n",
        "N_1(x,y;\\delta) = \\sum_{i=1}^n b_{1,i}(\\delta)t_{1,i}(x,y).\n",
        "$$\n",
        "\n",
        "Here, $n$ is your choice (start with $n=10$), $b_{1,i}$ is a neural network that takes $\\delta$ as input and outputs a scalar, and $t_{1,i}(x,y)$ is a multi-layer perceptron with 3 hidden layers, each with 128 units, and tanh activations, and Fourier features at the beginning. The same applies to $N_2(x,y;\\delta)$. This representation resembles an expansion in terms of basis functions.\n",
        "The same architecture appears in DeepONet.\n",
        "\n",
        "Plot the $x$ and $y$ displacement at $x=0.5, y=0.5$ as a function of $\\delta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngG4qagnXJ5X"
      },
      "source": [
        "*Put your answer here. Use as many markdown and code blocks as you want.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTkacSyNXJ5X"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}